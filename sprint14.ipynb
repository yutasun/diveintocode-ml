{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint14論文読解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) 物体検出の分野にはどういった手法が存在したか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPPnet、Fast R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Fasterとあるが、どういった仕組みで高速化したのか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RPNとFast R-CNNのたたみ込み機能を共有することにより高速化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) One-Stageの手法とTwo-Stageの手法はどう違うのか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-stageは物体検出からクラス分類までを一連の動作として学習するのに対し、　<br>\n",
    "two-stageは物体検出をクラス分類のアルゴリズムが分離しており、個別に学習する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) RPNとは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予め設定したアンカーボックスに対して領域提案を行い背景クラスに属するタイル配置されたアンカー ボックスを削除。\n",
    "残ったアンカー ボックスは信頼度スコアによってフィルター処理され、非最大抑制 (NMS) を使用して信頼度スコアが最も高いアンカー ボックスを選択する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5) RoIプーリングとは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNの畳み込み時に生成した画像に対して、領域提案を行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6) Anchorのサイズはどうするのが適切か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "マルチスケール検出を実現するには、64 × 64、128 × 128 および 256 × 256 などのさまざまなサイズのアンカー ボックスを指定する必要あり。<br>\n",
    "または学習データ内のオブジェクトのスケールが予測される場合は縦横比を厳密に表すサイズを指定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (7) 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MS COCOデータセットを利用しfast R-CNNを使用したベースラインよりも優れた検出精度を生成することができた。\n",
    "動作時間は領域提案で有効時間10ミリsec fastrcnnに比べて２０倍早い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (8) （アドバンス課題）Faster R-CNNよりも新しい物体検出の論文では、Faster R-CNNがどう引用されているか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1512.02325.pdf<br>\n",
    "単一のディープニューラルネットワークを使用して画像内のオブジェクトを検出する方法を示します。<br>\n",
    "SSDという名前の私たちのアプローチは、バウンディングボックスの出力スペースを、機能マップの場所<br>\n",
    "ごとに異なるアスペクト比とスケールでデフォルトのボックスのセットに離散化します。予測時に、<br>\n",
    "ネットワークは各デフォルトボックス内の各オブジェクトカテゴリの存在のスコアを生成し、<br>\n",
    "オブジェクトの形状によりよく一致するようにボックスを調整します。さらに、ネットワークは、<br>\n",
    "解像度が異なる複数の機能マップからの予測を組み合わせて、さまざまなサイズのオブジェクトを自然に処理します。<br>\n",
    "SSDモデルは、提案の生成とそれに続くピクセルまたは機能のリサンプリング段階を完全に排除し、<br>\n",
    "すべての計算を単一のネットワークにカプセル化するため、オブジェクトの提案を必要とする方法に比べて単純です。<br>\n",
    "これにより、SSDのトレーニングが容易になり、検出コンポーネントを必要とするシステムに簡単に統合できます。<br>\n",
    "PASCAL VOC、MS COCO、およびILSVRCデータセットの実験結果は、SSDが追加のオブジェクト提案ステップを利用する方法に匹敵する精度を持ち、<br>\n",
    "はるかに高速であると同時に、トレーニングと推論の両方に統一されたフレームワークを提供することを確認します。\n",
    "他のシングルステージ方式と比較して、SSDは入力画像サイズが小さくても精度がはるかに優れています。<br>\n",
    "にとって 入力画像のサイズが小さくても、SSDの精度ははるかに優れています。<br>\n",
    "にとって 入力画像のサイズが小さくても、SSDの精度ははるかに優れています。にとって300 × 300入力、<br>\n",
    "<span style=\"color: red; \">SSDはNvidia Titan Xで58 FPSのVOC2007テストで72.1％mAPを達成し、500 × 500入力では、SSDは75.1％mAPを達成し、<br>\n",
    "同等の最先端のFaster R-CNNモデルよりも優れています。</span>コードは、このhttps URLで入手でき ます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 論文要約"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アブストラクト<br>\n",
    "SPPnet やFast R-CNN のような進歩により、これらの検出ネットワークの実行時間が短縮され、現在は領域提案の計算がボトルネックになっています。<br>\n",
    "フルネットワークの畳み込み機能を検出ネットワークと共有するRegion Proposal Network（RPN）を導入し、ほぼ無負荷で領域提案を可能にします。<br> \n",
    "RPNは、各位置でオブジェクトの境界とオブジェクトのスコアを同時に予測する畳み込みネットワークです。<br>\n",
    "RPNは、高速R-CNNが検出に使用する高品質の領域提案を生成するためにエンドツーエンドでトレーニングされます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "イントロダクション<br>\n",
    "物体検出の最近の進歩は、領域提案手法および領域ベースの畳み込みニューラルネットワーク（R-CNN）の成功によって牽引されています。<br>\n",
    "領域計算のCNNは計算上高価でしたが、検出ネットワークと畳み込みを共有することにより、計算コストが大幅に削減されました。<br>\n",
    "直近のFast R-CNN は、領域提案に費やされた時間を無視すると、非常に深いネットワークを使用してほぼリアルタイムのレートを達成します。\n",
    "そのため領域提案は、最先端の検出システムにおけるテスト時の計算上のボトルネックです。\n",
    "地域提案方法は通常、安価な機能と経済的な推論スキームに依存しています。最も人気のある方法の1つである選択的検索は、<br>\n",
    "設計された低レベルの機能に基づいて、スーパーピクセルを隅々までにマージします。しかし、効率的な検出ネットワーク？と比較すると選択的検索は<br>\n",
    "CPU実装時に画像ごとに2秒という、桁違いに遅いパフォーマンスです。 EdgeBoxesは現在、プロポーザルの品質と速度の最良のトレードオフを提供し、<br>\n",
    "画像あたり0.2秒です。それでも、領域提案のステップは、検出ネットワークと同じくらいの実行時間を消費します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高速リージョンベースのCNNはGPUを活用し、研究で使用されるリージョン提案方法はCPUに実装されるため、このようなランタイム比較は不公平になります。提案計算を高速化する明白な方法は、GPUに再実装することです。これは効果的なエンジニアリングソリューションかもしれませんが、再実装はダウンストリーム検出ネットワークを無視するため、計算を共有する重要な機会を逃します。\n",
    "このホワイトペーパーでは、アルゴリズムの変更（深い畳み込みニューラルネットワークを使用した提案の計算）が、検出ネットワークの計算を考慮すると提案の計算がほぼ無料であるエレガントで効果的なソリューションにつながることを示します。この目的のために、畳み込み層を最新のオブジェクト検出ネットワークと共有する新しい領域提案ネットワーク（RPN）を導入します[1]、[2]。テスト時に畳み込みを共有することにより、計算提案の限界費用は小さくなります（たとえば、画像あたり10ミリ秒）。\n",
    "私たちの観察では、高速R-CNNのような領域ベースの検出器で使用される畳み込み特徴マップは、領域提案の生成にも使用できます。これらの畳み込み機能の上に、通常のグリッド上の各位置で領域の境界と客観性スコアを同時に回帰するいくつかの追加の畳み込み層を追加することにより、RPNを構築します。したがって、RPNは一種の完全な畳み込みネットワーク（FCN）[7]であり、検出提案を生成するタスク専用にエンドツーエンドでトレーニングできます。\n",
    "RPNは、広範囲のスケールとアスペクト比で領域提案を効率的に予測するように設計されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像のピラミッド（図1、a）またはフィルターのピラミッド（図1、b）に、複数のスケールとアスペクト比で参照として機能する新しい「アンカー」ボックスを導入します。このスキームは、回帰参照のピラミッドと考えることができます（図1、c）。これにより、複数のスケールまたはアスペクト比の画像またはフィルターの列挙が回避されます。このモデルは、単一スケールのイメージを使用してトレーニングおよびテストを行うとパフォーマンスが向上するため、実行速度が向上します。\n",
    "RPNを高速R-CNN [2]オブジェクト検出ネットワークと統合するために、提案を固定したまま、領域提案タスクの微調整とオブジェクト検出の微調整を交互に行うトレーニングスキームを提案します。このスキームは迅速に収束し、両方のタスク間で共有される畳み込み機能を備えた統合ネットワークを生成します。高速R-CNNを使用したRPNが高速R-CNNを使用した選択的検索の強力なベースラインよりも優れた検出精度を生成するPASCAL VOC検出ベンチマーク[11]でメソッドを包括的に評価します。一方、この方法では、テスト時の選択的検索のほぼすべての計算負荷が軽減されます。提案の有効な実行時間はわずか10ミリ秒です。 [3]の高価な非常に深いモデルを使用すると、GPUでの検出方法は5fps（すべてのステップを含む）のフレームレートであり、速度と精度の両方の点で実用的なオブジェクト検出システムです。また、MS COCOデータセットに関する結果[12]を報告し、COCOデータを使用してPASCAL VOCの改善点を調査します。コードはhttps://github.com/shaoqingren/faster_ rcnn（MATLAB内）およびhttps://github.com/で公開されています。\n",
    "rbgirshick / py-faster-rcnn（Python）。\n",
    "この原稿の予備版は以前に公開されていました[10]。それ以来、RPNおよびFaster R-CNNのフレームワークが採用され、3Dオブジェクト検出[13]、部分ベース検出[14]、インスタンスセグメンテーション[15]、画像キャプション[ 16]。当社の高速で効果的なオブジェクト検出システムは、comにも組み込まれています"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinterestなどの慈悲深いシステム[17]、ユーザーエンゲージメントの改善が報告されています。\n",
    "ILSVRCおよびCOCO 2015コンペティションで、より速く\n",
    "R-CNNとRPNは、いくつかの1位の基礎です\n",
    "ImageNet検出のトラックのエントリ[18]、Ima-\n",
    "geNetローカリゼーション、COCO検出、COCO seg-\n",
    "言及。 RPNは地域の提案を完全に学習します\n",
    "データから、したがって、より深いから簡単に利益を得ることができます\n",
    "より表現力豊かな機能（101層など\n",
    "[18]で採用された残留ネット）。 より高速なR-CNNおよびRPN\n",
    "これらのいくつかの他の主要なエントリによっても使用されます\n",
    "2\n",
    "コンペティション。 これらの結果は、我々の方法が\n",
    "は、実際に使用するためのコスト効率の高いソリューションであるだけでなく、オブジェクト検出の精度を向上させる効果的な方法でもあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実装\n",
    "オブジェクトの提案。オブジェクトの提案方法に関する多くの文献があります。オブジェクト提案方法の包括的な調査と比較は、[19]、[20]、[21]にあります。広く使用されているオブジェクトの提案方法には、スーパーピクセルのグループ化に基づくもの（たとえば、選択的検索[4]、CPMC [22]、MCG [23]）およびスライドウィンドウに基づくもの（たとえば、ウィンドウ内のオブジェクト性[24]、EdgeBoxes [ 6]）。オブジェクトの提案方法は、検出器とは独立した外部モジュールとして採用されました（たとえば、Selective Search [4]オブジェクト検出器、R-CNN [5]、およびFast R-CNN [2]）。\n",
    "オブジェクト検出用のディープネットワーク。 R-CNNメソッド[5]は、CNNをエンドツーエンドでトレーニングして、提案領域をオブジェクトカテゴリまたはバックグラウンドに分類します。 R-CNNは主に分類子として機能し、オブジェクトの境界を予測しません（境界ボックス回帰による洗練を除く）。その精度は、地域提案モジュールのパフォーマンスに依存します（[20]の比較を参照）。いくつかの論文では、オブジェクトの境界ボックスを予測するためにディープネットワークを使用する方法が提案されています[25]、[9]、[26]、[27]。 OverFeatメソッド[9]では、完全に接続されたレイヤーは、単一のオブジェクトを想定したローカリゼーションタスクのボックス座標を予測するようにトレーニングされます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "するための畳み込み層へ。 MultiBoxメソッド[26]、[27]は、最後に完全に接続されたレイヤーが複数のクラスに依存しないボックスを同時に予測するネットワークからリージョン提案を生成し、OverFeatの「シングルボックス」方式を一般化します。これらのクラスに依存しないボックスは、R-CNN [5]の提案として使用されます。 MultiBox提案ネットワークは、完全な畳み込み方式とは対照的に、単一の画像クロップまたは複数の大きな画像クロップ（たとえば、224 x 224）に適用されます。 MultiBoxは、提案ネットワークと検出ネットワーク間で機能を共有しません。 OverFeatとMultiBoxについては、後でメソッドのコンテキストで詳しく説明します。作業と並行して、DeepMaskメソッド[28]はセグメンテーションの提案を学習するために開発されました。\n",
    "畳み込みの共有計算[9]、[1]、[29]、[7]、[2]は、効率的でありながら正確な視覚認識のための注目を集めています。 OverFeat論文[9]は、分類、位置特定、検出のために画像ピラミッドから畳み込み特徴を計算します。共有畳み込み特徴マップ上の適応サイズプーリング（SPP）[1]は、効率的な領域ベースのオブジェクト検出[1]、[30]およびセマンティックセグメンテーション[29]のために開発されています。 Fast R-CNN [2]は、共有畳み込み機能のエンドツーエンド検出器トレーニングを可能にし、説得力のある精度と速度を示します。\n",
    "3より速いR-CNN\n",
    "Faster R-CNNと呼ばれるオブジェクト検出システムは、2つのモジュールで構成されています。最初のモジュールは領域を提案する完全な畳み込みネットワークであり、2番目のモジュールは提案された領域を使用する高速R-CNN検出器です[2]。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "オブジェクト注意用の単一の統合ネットワーク（図2）。「注意」[31]メカニズムを備えた最近人気のあるニューラルネットワークの用語を使用して、RPNモジュールはFast R-CNNモジュールにどこを見ればセクション3.1では、地域提案のためのネットワークの設計と特性を紹介します。セクション3.2では、機能を共有して両方のモジュールをトレーニングするアルゴリズムを開発します。\n",
    "3.1地域提案ネットワーク\n",
    "地域提案ネットワーク（RPN）が画像を取得します\n",
    "（任意のサイズの）入力として、一連の長方形を出力します\n",
    "3つのオブジェクト提案。それぞれにオブジェクト性スコアがあります。私達\n",
    "このセクションで説明する完全な畳み込みネットワーク[7]でこのプロセスをモデル化します。最終的な目標は高速R-CNNオブジェクト検出ネットワークと計算を共有することであるため[2]、両方のネットが畳み込み実験では、5つの共有可能な畳み込み層を持つZeiler and Fergusモデル[32]（ZF）と、13の共有可能な畳み込み層を持つSimonyan and Zissermanモデル[3 ]（VGG-16）を調査します。\n",
    "地域の提案を生成するために、最後の共有畳み込み層によって出力された畳み込み特徴マップ上に小さなネットワークをスライドさせます。この小さなネットワークは、入力畳み込み特徴マップのn×n空間ウィンドウを入力として受け付けます各スライディングウィンドウは、低次元の再帰にマッピングされます（ZFの場合は256-d、VGGの場合は512-d、ReLU [33]が後に続きます）。この機能は、ボックス回帰層（reg ）とボックス分類層（cls）の2つの兄弟の完全に接続された層に供給されます。このホワイトペーパーでは、n = 3を使用します。入力画像の有効な受容野は大きいことに注意してください（ZFおよびVGGでそれぞれ171および228ピクセル）。このミニネットワークは、図3（左）の単一の位置に示されています。ミニネットワークはスライディングウィンドウ方式で動作するため、完全に接続されたレイヤーはすべての空間ロケーションで共有されることに注意してください。このアーキテクチャは、n×n畳み込み層とそれに続く2つの兄弟の1×1畳み込み層（それぞれregおよびcls用）で自然に実装されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.1アンカー\n",
    "各スライディングウィンドウの場所で、同時に\n",
    "複数の地域の提案を予測します。ここで、\n",
    "各場所の最大提案数は\n",
    "kとして示されます。 したがって、regレイヤーには4k出力のエンコードがあります\n",
    "k個のボックスの座標、およびclsレイヤーは、オブジェクトの確率を推定するかどうかを示す2k個のスコアを出力します\n",
    "各提案のためのオブジェクト。 k個の提案は、k個の参照ボックスに関連してパラメーター化されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アンカー。アンカーは、問題のスライディングウィンドウの中央に配置され、スケールとアスペクト比に関連付けられます（図3左）。デフォルトでは、3つのスケールと3つのアスペクト比を使用して、各スライド位置でk = 9アンカーを生成します。サイズW×H（通常約2,400）の畳み込み特徴マップの場合、合計でW H kアンカーがあります。\n",
    "翻訳不変アンカー\n",
    "このアプローチの重要な特性は、アンカーと、アンカーに関連する提案を計算する関数の両方の点で、変換不変であることです。画像内のオブジェクトを翻訳する場合、提案は翻訳する必要があり、同じ機能がどちらの場所でも提案を予測できるはずです。この翻訳不変のプロパティはグアランです\n",
    "5\n",
    "私たちの方法で食べた比較として、MultiBox\n",
    "method [27]はk-meansを使用して800個のアンカーを生成しますが、これらは変換不変ではありません。したがって、MultiBoxは、オブジェクトが翻訳された場合に同じ提案が生成されることを保証しません。\n",
    "平行移動不変プロパティは、モデルのサイズも縮小します。 MultiBoxには（4 + 1）×800次元の完全に接続された出力層がありますが、k = 9アンカーの場合、この方法には（4 + 2）×9次元の畳み込み出力層があります。その結果、出力レイヤーには2.8×104パラメーター（VGG-16では512×（4 + 2）×9）、6.1×106パラメーター（1536×（4 + 1）があるMultiBoxの出力レイヤーよりも2桁少ない）×MultiBox [27]のGoogleNet [34]に対して800。フィーチャ投影レイヤーを検討する場合、提案レイヤーの数はまだ1桁少なくなっています\n",
    "6\n",
    "MultiBoxよりも多くのパラメータ。私たちの方法を期待しています\n",
    "PASCAL VOCのような小さなデータセットでオーバーフィットするリスクを減らすため。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
