{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#必要なクラスをインポート\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 今日使用データをインプット\n",
    "df = pd.read_csv('/Users/suzukiyuuta/Downloads/train.csv')#教師データを読み込む\n",
    "\n",
    "df_XY = df.loc[:,['GrLivArea','YearBuilt','SalePrice']]\n",
    "# display(df_XY)\n",
    "np_XY = df_XY.values\n",
    "np_X = np_XY[:, :2]\n",
    "np_Y = np_XY[:, 2:3]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# ndarray変換\n",
    "X_array = np_X\n",
    "y_array = np_Y\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_array, y_array, test_size=0.25, random_state=0)\n",
    "\n",
    "# バイアス＝TRUEの時は下記をXとして扱う\n",
    "# np_1 = np.ones((1460,1))\n",
    "# np_1X = np.concatenate([np_1, np_X], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[54.88135039 71.51893664 60.27633761]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[243085.76722723, 209417.82249835, 248400.65373644, ...,\n",
       "        284405.56437704, 194691.15337931, 208325.66916485]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初期推定\n",
    "# np.random.seed(0) \n",
    "# param_vec = np.random.uniform(0, 100, (1, 3))\n",
    "# y = param_vec @ np_1X.T\n",
    "# y = y.T\n",
    "# print(y)\n",
    "num_iter: int = 100\n",
    "lr: float = 0.000001\n",
    "no_bias: bool = False\n",
    "verbose : bool = True\n",
    "\n",
    "X = np_X\n",
    "\n",
    "np_1 = np.ones((X.shape[0],1)) # 行列の長さを自動取得する\n",
    "if no_bias != True:\n",
    "    X = np.concatenate([np_1, X], 1) # バイアス＝TRUEの時は下記をXとして扱う\n",
    "else:\n",
    "    pass\n",
    "np.random.seed(0) #本来は与えられるパラメータベクトル\n",
    "param_vec = np.random.uniform(0, 100, (1, X.shape[1]))\n",
    "\n",
    "print(type(X))\n",
    "print(param_vec)\n",
    "\n",
    "\n",
    "y_pred = param_vec @ X.T\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】仮定関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数化\n",
    "# クラスパラメータ値を借りで入力\n",
    "# num_iter: int = 100\n",
    "# lr: float = 0.000001\n",
    "# no_bias: bool = False\n",
    "# verbose : bool = True\n",
    "\n",
    "def _linear_hypothesis(self,X):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    h0 = np.dot(X, self.coef_.T)\n",
    "    # coef_.Tでベクトルを転置すると予期せぬ結果が発生する\n",
    "    # →　だからベクトルの内積時は次元追加の方が良い（newaxis or reshape）\n",
    "    \n",
    "    return h0\n",
    "#     np_1 = np.ones((X.shape[0],1)) # 行列の長さを自動取得する\n",
    "#     if no_bias != True:\n",
    "#         X = np.concatenate([np_1, X], 1) # バイアス＝TRUEの時は下記をXとして扱う\n",
    "#     else:\n",
    "#         pass\n",
    "#     np.random.seed(0) #本来は与えられるパラメータベクトル\n",
    "#     param_vec = np.random.uniform(0, 100, (1, X.shape[1]))\n",
    "#     y_pred = (param_vec @ X.T).T\n",
    "#     pass\n",
    "#     return y_pred\n",
    "\n",
    "# _linear_hypothesis(np_X)\n",
    "# yp = _linear_hypothesis(np_X)\n",
    "# print(yp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】最急降下法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gradient_descent(self, X, error):\n",
    "    stu = 0.0000000001\n",
    "\n",
    "    self.coef_ = self.coef_ - stu/X.shape[0]*(error.T @ X).T\n",
    "\n",
    "# pv_next = param_vec\n",
    "# for n in range(num_iter):\n",
    "#     param_da = pv_next[0]\n",
    "#     for j in range(X.shape[1]):\n",
    "#         for i in range(X.shape[0]):\n",
    "#             result0 += (param_da*X[i] - np_Y[i])*X[i]\n",
    "#         pv0 = param_da - stu/X.shape[0]*result0\n",
    "# #         print(- stu/X.shape[0]*result0)\n",
    "#         pv_next = np.insert(pv_next,0,pv0)\n",
    "# print(pv_next)\n",
    "\n",
    "# X.shape[0] = 1460\n",
    "# X.shape[1] = 3\n",
    "# error.T.shape\n",
    "# X[:, 0].shape\n",
    "# X.shape[0] = 1460\n",
    "# X.shape[1] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】平均二乗誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.51645086e+09])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MSE(y_pred, y):\n",
    "    suma = 0\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        suma += (y_pred[i] - y[i]) **2\n",
    "    mse = (1/y_pred.shape[0])*suma\n",
    "    \n",
    "    pass\n",
    "    return mse\n",
    "\n",
    "MSE(yp,np_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      学習用データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証用データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter, lr, bias=None, verbose=None):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        #パラメーターの初期値（平均０、分散１の正規分布）\n",
    "        self.coef_ = np.random.normal(0, 1, X.shape[1])\n",
    "        self.stu = 0.0000000001\n",
    "#         print(self.coef_)\n",
    "#         self.coef_ = None # とすることで、fitをを呼び出さなくてもcoefが使用できる（先にpredictやる時とか）\n",
    "        # self/h0も同様\n",
    "\n",
    "    def _linear_hypothesis2(self,X):\n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          学習データ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果\n",
    "\n",
    "        \"\"\"\n",
    "#         print(self.coef_)\n",
    "        coef_T = (self.coef_).T\n",
    "        \n",
    "        h0 = np.dot(X, coef_T)\n",
    "        # coef_.Tでベクトルを転置すると予期せぬ結果が発生する\n",
    "        # →　だからベクトルの内積時は次元追加の方が良い（newaxis or reshape）\n",
    "\n",
    "        return h0\n",
    "    def _gradient_descent2(self,X,error):\n",
    "\n",
    "        self.coef_ = self.coef_ - self.stu/X.shape[0]*(error.T @ X).T\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証用データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        \n",
    "        # yの一次元化\n",
    "        y = y.ravel()\n",
    "        y_val = y_val.ravel()\n",
    "        \n",
    "        # 切片列を追加（切片の有無を選べる）\n",
    "        if not self.bias:   \n",
    "            X = np.concatenate([np.ones([X.shape[0], 1]), X], axis=1)\n",
    "            X_val = np.concatenate([np.ones([X_val.shape[0], 1]), X_val], axis=1)\n",
    "        \n",
    "#         print(self.coef_)\n",
    "        \n",
    "        for iter_count in range(self.iter):\n",
    "            if self.verbose:\n",
    "                #verboseをTrueにした際は学習過程を出力\n",
    "                print(\"{}回目の学習\".format(iter_count))\n",
    "            \n",
    "            # 過程関数\n",
    "#             print(iter_count)\n",
    "            h0 = self._linear_hypothesis2(X)\n",
    "            h0_val = self._linear_hypothesis2(X_val)\n",
    "            # _linear_hypothesis　→　これだけでh0の更新、fit内部ではself.h0で更新後の値が呼び出せる、retunいらない\n",
    "            \n",
    "            # 最急降下法（error算出→勾配算出）\n",
    "            error = h0 - y\n",
    "            self._gradient_descent2(X,error)\n",
    "#             print(self.coef_)\n",
    "            # self._gradient_descent →　これだけでself.coef_の更新、fit内部ではself.coef_で更新後の値が呼び出せる、retunいらない\n",
    "            \n",
    "            # costの記録\n",
    "            self.loss[iter_count] = loss_cal(h0 , y)\n",
    "            self.val_loss[iter_count] = loss_cal(h0_val , y_val)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        if not self.bias:   \n",
    "            X = np.concatenate([np.ones([X.shape[0], 1]), X], axis=1)\n",
    "        h0 = np.dot(X, self.coef_.T)\n",
    "        \n",
    "        return h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "slrg = ScratchLinearRegression(5000, 0.001)\n",
    "slrg.fit(X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([225827.48025329, 178585.90654112, 160476.1259371 , 202441.74633495,\n",
       "       156064.28761845, 149440.89578048, 176353.64733044, 168323.46453749,\n",
       "       324982.28615682, 158266.96586706, 170754.05203768, 185449.22855851,\n",
       "       201648.12548581, 146346.72451622, 154378.98324645, 166336.61111024,\n",
       "       198313.89703732, 152201.73408536, 162542.2852792 , 189525.27696609,\n",
       "       169594.8698082 , 145685.21668943, 141978.88153675, 176523.14686574,\n",
       "       195054.50511711, 183657.04974447, 181390.74018517, 133127.63637227,\n",
       "       187944.70759645, 160964.86156667, 189273.26235642, 191034.53647896,\n",
       "       147510.24912745, 212349.76867343, 205234.43204637, 174892.91604571,\n",
       "       181055.0137765 , 145713.79143406, 207353.39849597, 233041.94927391,\n",
       "       207781.52146717, 168511.72083165, 168621.86793561, 194625.24892367,\n",
       "       241613.61130154, 187206.03329449, 142010.7924457 , 146515.15433167,\n",
       "       185701.30667058, 146746.27274278, 235786.17025959, 154812.70882645,\n",
       "       168362.04777507, 139453.69453195, 184338.57455717, 145166.70959058,\n",
       "       169750.01846879, 192943.28071599, 157086.88743902, 139865.39069115,\n",
       "       153768.07958508, 153108.71119797, 162472.9243549 , 158674.1926397 ,\n",
       "       186330.96709082, 174460.26018556, 147164.57772823, 187750.97569828,\n",
       "       160734.749373  , 189471.46364115, 174613.33290886, 153665.6745296 ,\n",
       "       147750.17930688, 174124.59727929, 148749.67998683, 185317.17903856,\n",
       "       150991.94769045, 146166.14676812, 225685.54924518, 166104.35947689,\n",
       "       148802.55059672, 145132.59573956, 165539.59059438, 152201.73408536,\n",
       "       253542.5374159 , 169855.82319098, 159210.19627038, 171494.86577932,\n",
       "       163974.44181929, 154797.28823189, 186686.5199782 , 180198.5773269 ,\n",
       "       177416.96982828, 195760.13528788, 166097.81415305, 163470.22209276,\n",
       "       177189.12407908, 182151.25340072, 144718.69663827, 177769.12304894,\n",
       "       189624.47286205, 198833.473856  , 167624.50669535, 172919.21676854,\n",
       "       135412.76619284, 222732.17576678, 170576.81045391, 147269.12222339,\n",
       "       177240.86146674, 166142.81570967, 133348.80979282, 152426.24367023,\n",
       "       200694.82308713, 155696.58679843, 175345.33488218, 178910.68174179,\n",
       "       222114.66327917, 153074.59734695, 207920.24331575, 200821.46050548,\n",
       "       157177.20806427, 172787.16724859, 150395.3314014 , 199796.59424043,\n",
       "       182082.01948123, 177150.6043439 , 208846.04068964, 168227.79531304,\n",
       "       165255.72857817, 177672.32060226, 169892.13998409, 165206.19413259,\n",
       "       213343.73024698, 173819.64855732, 144718.69663827, 186587.45108704,\n",
       "       174125.60349673, 170295.02437498, 145723.67292221, 182462.87445132,\n",
       "       157949.86921246, 156832.66988728, 212939.71263385, 153798.92077419,\n",
       "       164183.53080961, 177462.0983897 , 176452.7162216 , 153511.59558886,\n",
       "       190516.09288251, 177374.04420893, 172197.09628338, 188194.58276643,\n",
       "       192997.22104573, 207275.09879856, 182117.1395497 , 240238.7312555 ,\n",
       "       156237.05981567, 174943.45670874, 159313.7980505 , 176469.206536  ,\n",
       "       144770.43402593, 160198.74574232, 181849.76784788, 149474.00341407,\n",
       "       181750.69895671, 174426.08283213, 174077.20227338, 219374.84817765,\n",
       "       170947.78393585, 187186.27031817, 169963.64034806, 179910.18242173,\n",
       "       168423.73015329, 159121.13587217, 150033.16968778, 156906.37319333,\n",
       "       157575.6230686 , 231610.92595605, 164431.13953512, 156090.7229234 ,\n",
       "       208200.95967485, 196923.59639672, 154713.57643288, 188241.91426993,\n",
       "       143017.97167172, 188155.99952885, 150811.43344476, 164215.50522096,\n",
       "       173230.77431674, 145685.21668943, 152201.73408536, 168570.06704555,\n",
       "       179715.38080373, 148540.5909965 , 160730.34348884, 152328.30800131,\n",
       "       133127.63637227, 157670.2860756 , 186508.14517219, 169587.19126213,\n",
       "       167626.70963743, 163680.50780772, 138906.61268848, 153850.65816185,\n",
       "       194629.52780303, 232342.92792938, 163578.10275224, 210120.71862228,\n",
       "       192042.84892721, 141821.40292929, 158861.37921403, 185303.96138609,\n",
       "       152402.01130736, 138376.0211594 , 193732.49568097, 219554.2292011 ,\n",
       "       172176.20008482, 237977.7702954 , 185812.52349437, 133231.11114759,\n",
       "       175353.01342826, 170769.40912984, 179805.51092177, 144822.17141359,\n",
       "       178330.61926953, 204975.74510807, 199371.74393115, 195235.0193628 ,\n",
       "       162679.87390554, 170093.55042833, 152350.2739197 , 156383.46021033,\n",
       "       144770.43402593, 157652.72604137, 194801.35728521, 170259.71379931,\n",
       "       190893.61168829, 142355.33062269, 158208.55615076, 174615.47234854,\n",
       "       164333.2038662 , 186391.5162468 , 191549.70741348, 191993.31448163,\n",
       "       164743.83030556, 156642.21065103, 170012.1050738 , 182043.49974604,\n",
       "       165159.86884652, 174305.11152498, 172188.28451506, 199830.77159386,\n",
       "       142235.30203058, 249662.42384857, 169026.95526858, 194625.24892367,\n",
       "       143524.33083793, 181554.76411647, 266051.71650972, 383360.29835645,\n",
       "       189561.72076399, 175165.82685393, 190007.46727183, 162396.89110197,\n",
       "       207065.0035908 , 191416.52467129, 235965.55128304, 125454.13968894,\n",
       "       202054.21903622, 187798.30720178, 172507.45710694, 202676.13740798,\n",
       "       174918.15462603, 180948.20283686, 209332.44637234, 206909.79142782,\n",
       "       189636.55729229, 186558.74933761, 200173.10682877, 165512.08556959,\n",
       "       146308.20478103, 201758.20908737, 174476.75049995, 177802.16718013,\n",
       "       167881.05419397, 206743.50105204, 162357.36514935, 188260.60752641,\n",
       "       222868.69467329, 224251.12626061, 135439.20149779, 154366.83531382,\n",
       "       194384.18552201, 145790.83090443, 147137.00920104, 187240.21064791,\n",
       "       179857.37531423, 164161.56489122, 167245.85466733, 173562.09484126,\n",
       "       151016.18005333, 160753.50613187, 185657.31133139, 171197.65910583,\n",
       "       192807.83152932, 169203.00012771, 156360.3610697 , 173268.16082969,\n",
       "       175957.37176579, 163239.10368165, 152402.01130736, 164568.85516627,\n",
       "       187777.28399843, 166012.9056294 , 167632.18524143, 145685.21668943,\n",
       "       215675.18535361, 161369.94889964, 173721.7128884 , 201120.74311625,\n",
       "       158676.33207938, 185650.70250516, 149462.92520128, 251999.22755441,\n",
       "       188055.73391305, 199076.74019975, 149487.22106655, 194827.79259016,\n",
       "       182329.62820674, 158217.36791908, 149030.39634592, 197771.221078  ,\n",
       "       180478.09696136, 169022.54938442, 173349.60618422, 155370.80538031,\n",
       "       156933.87821812, 173865.91034098, 169482.58326457, 153748.25310637,\n",
       "       192393.99593044, 163603.46833735, 186613.75938719, 200717.98573016,\n",
       "       162120.70763184, 176790.58206996, 156600.29124913, 152798.28687201,\n",
       "       144152.85803593, 149097.55432813, 191308.64401181, 232161.34396384,\n",
       "       146475.50137425, 144885.99323149, 169597.13625268, 206616.99063849,\n",
       "       228586.05211368, 187790.50165091, 184276.95568136, 207501.93833031,\n",
       "       235395.24329414, 195175.60342907, 179013.08679727, 181653.83300763,\n",
       "       138246.11107913])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slrg.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.29963088e+09])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(slrg.predict(X_valid),y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iter_list = [i for i in range(slrg.iter)]\n",
    "plt.scatter(iter_list, slrg.loss, label=\"train\")\n",
    "plt.scatter(iter_list, slrg.val_loss, label=\"valid\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iter')\n",
    "plt.title('madel loss (StandardScaler)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slrg.coef_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】目的関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_cal(y_pred , y):\n",
    "    \"\"\"\n",
    "    損失関数の計算と記録\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)\n",
    "      推定した値\n",
    "    y : 次の形のndarray, shape (n_samples,)\n",
    "      正解値\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    cost : numpy.float\n",
    "      平均二乗誤差\n",
    "    \"\"\"\n",
    "    loss = ((y_pred-y)**2).sum() / X.shape[0] / 2\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _linear_hypothesis(self, X):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "\n",
    "    \"\"\"\n",
    "    pass\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-b38e3ac97ecc>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-b38e3ac97ecc>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    def fit(self, X, y), X_val=None, y_val=None):\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "    \"\"\"\n",
    "    num_iter: int = 100\n",
    "    lr: float = 0.000001\n",
    "    no_bias: bool = True\n",
    "    verbose : bool = True\n",
    "\n",
    "    \"\"\"\n",
    "    self.coef_ : 次の形のndarray, shape (特徴量の数,)\n",
    "    self.loss : 次の形のndarray, shape (学習用データに対する損失の記録を格納,)\n",
    "    self.val_loss : 次の形のndarray, shape (検証用データに対する損失の記録を格納,)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter, lr, bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "\n",
    "    def fit(self, X, y), X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証用データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        pass\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
