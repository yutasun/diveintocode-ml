{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インポート\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNISTデータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# データセットインストール\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平滑化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　動作確認なし\n",
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.005):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self):\n",
    "        W = self.sigma * np.random.randn(self.F)\n",
    "        pass\n",
    "        return W\n",
    "    \n",
    "    def B(self):\n",
    "        B = self.sigma * np.random.randn(self.S)\n",
    "        pass\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.001):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        layer.W = layer.W - self.lr*layer.dW\n",
    "        layer.B = layer.B - self.lr*layer.dB.mean(axis=0)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    \"\"\"\n",
    "    入出力サイズN_inからN_outへの\n",
    "    Parameters\n",
    "    ----------\n",
    "    N_in : int\n",
    "      入力サイズ数\n",
    "    N_out : int\n",
    "      出力サイズ数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def N_out_cal():\n",
    "        N_out = (self.N_in + 2*self.P - self.F)/self.S + 1\n",
    "        self.N_out = int(N_out)\n",
    "    def __init__(self, N_in, initializer=SimpleInitializer, optimizer=SGD, F=3,S=1,P=0):\n",
    "        self.F = F\n",
    "        self.S = S\n",
    "        self.P = P\n",
    "        self.initializer = SimpleInitializer\n",
    "        self.optimizer = optimizer\n",
    "        self.N_out_cal()\n",
    "        self.N_in = N_in\n",
    "        \n",
    "        ini = self.initializer()\n",
    "        #初期値を決める\n",
    "        # WとBを決定する\n",
    "        self.W = ini.W(self.F)\n",
    "        self.B = ini.B(self.S)        \n",
    "        \n",
    "        opt = self.optimizer\n",
    "        #最適化処理をインスタンス化\n",
    "        \n",
    "        pass\n",
    "    def forward(self, Z):\n",
    "        self.Z = Z\n",
    "        self.creat_index\n",
    "        A = np.empty((0,0))\n",
    "        for k in range(self.Z.shape[0] - self.W.shape[0] + 1):\n",
    "            ak = self.Zx[self.indexes[k]]@self.W.T + self.B\n",
    "            A = np.append(A,ak)\n",
    "        A = A.astype(np.int)\n",
    "        self.A = A\n",
    "\n",
    "        pass\n",
    "        return A\n",
    "    \n",
    "    def creat_index(self):\n",
    "        for i in range(self.Z.shape[0] - self.W.shape[0] + 1):\n",
    "            for j in range(self.W.shape[0]):\n",
    "                self.index_add = np.append(self.index_add,[j + i])\n",
    "\n",
    "        self.indexes = self.index_add.reshape(self.Z.shape[0] - self.W.shape[0] + 1,self.W.shape[0])\n",
    "        self.indexes = self.indexes_test.astype(\"int\")  \n",
    "\n",
    "    def backward(self, dA):\n",
    "        self.dA = dA\n",
    "        self.dB = np.array(np.sum(self.dA))\n",
    "        self.dW = np.zeros((w.shape[0],))\n",
    "        self.dZ = np.zeros((self.Z.shape[0],))\n",
    "        for l in range(self.dA.shape[0]):\n",
    "            delta_w_l = self.dA[l]*x[self.indexes[l]]\n",
    "            self.dW = self.dW + delta_w_l\n",
    "        \n",
    "        for h in range(self.dA.shape[0]):\n",
    "            delta_z_h = delta_a[h]*w\n",
    "            for m in range(self.dW.shape[0]):\n",
    "                self.dZ[m + h] += delta_z_h[m]\n",
    "        \n",
    "        pass\n",
    "        # 更新\n",
    "        self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】1次元畳み込み後の出力サイズの計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$N_{out} =  \\frac{N_{in}+2P-F}{S} + 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N out : 出力のサイズ（特徴量の数）<br>\n",
    "N in : 入力のサイズ（特徴量の数）<br>\n",
    "P : ある方向へのパディングの数<br>\n",
    "F : フィルタのサイズ<br>\n",
    "S : ストライドのサイズ<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "def N_out_cal(N_in,P,F,S):\n",
    "    N_out = (N_in + 2*P - F)/S + 1\n",
    "    return int(N_out)\n",
    "print(N_out_cal(4,0,3,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】小さな配列での1次元畳み込み層の実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "#行列をインデックスで抽出するテスト\n",
    "x = np.array([1, 2, 3, 4])\n",
    "indexes = np.array([[0, 1, 2], [1, 2, 3]]).astype(np.int)\n",
    "print(x[indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#インデックスアレイを作る\n",
    "class index_array():\n",
    "    def __init__(self):\n",
    "        self.indexes_test = np.empty((0,0))\n",
    "        self.index_add = np.empty((0,0))\n",
    "    def creat(self, m, l):\n",
    "        for i in range(m.shape[0] - l.shape[0] + 1):\n",
    "            for j in range(l.shape[0]):\n",
    "                self.index_add = np.append(self.index_add,[j + i])\n",
    "        print(self.index_add)\n",
    "        self.indexes_test = self.index_add.reshape(m.shape[0] - l.shape[0] + 1,l.shape[0])\n",
    "        indexes_test = self.indexes_test.astype(\"int\")\n",
    "        return indexes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "cl = index_array()\n",
    "indexes = cl.creat(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class index_array_test():\n",
    "    def __init__(self):\n",
    "        self.indexes_test = np.empty((0,0))\n",
    "        self.index_add = np.empty((0,0))\n",
    "    def creat(self, m, l):\n",
    "        for i in range(m - l + 1):\n",
    "            for j in range(l):\n",
    "                self.index_add = np.append(self.index_add,[j + i])\n",
    "\n",
    "        self.indexes_test = self.index_add.reshape(m.shape[0] - l.shape[0] + 1,l.shape[0])\n",
    "        indexes_test = self.indexes_test.astype(\"int\")\n",
    "        return indexes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# フォワードプロテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35 50]\n"
     ]
    }
   ],
   "source": [
    "# フォワードプロテスト\n",
    "a = np.empty((0,0))\n",
    "for k in range(x.shape[0] - w.shape[0] + 1):\n",
    "    ak = x[indexes[k]]@w.T + b\n",
    "    a = np.append(a,ak)\n",
    "a = a.astype(np.int)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# バックプロパゲーションテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dAを以下で設定する\n",
    "delta_a = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# dBの出力テスト\n",
    "delta_b = np.array(np.sum(delta_a))\n",
    "print(delta_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50  80 110]\n"
     ]
    }
   ],
   "source": [
    "# dWの出力テスト\n",
    "delta_w = np.zeros((w.shape[0],))\n",
    "for l in range(delta_a.shape[0]):\n",
    "    delta_w_l = delta_a[l]*x[indexes[l]]\n",
    "#     print(delta_w_l.shape)\n",
    "    delta_w = delta_w + delta_w_l\n",
    "delta_w = delta_w.astype(np.int)\n",
    "print(delta_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30 110 170 140]\n"
     ]
    }
   ],
   "source": [
    "# dXの出力テスト\n",
    "delta_x = np.zeros((x.shape[0],))\n",
    "for h in range(delta_a.shape[0]):\n",
    "    delta_x_h = delta_a[h]*w\n",
    "    for m in range(w.shape[0]):\n",
    "#         print(delta_x_h[m])\n",
    "        delta_x[m + h] += delta_x_h[m]\n",
    "delta_x = delta_x.astype(np.int)\n",
    "print(delta_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[[1., 2., 3.],\n",
    "        [4., 5., 6.]],\n",
    "\n",
    "       [[7., 8., 9.],\n",
    "        [10., 11., 12.]],\n",
    "\n",
    "       [[13., 14., 15.],\n",
    "        [16., 17., 18.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ones_Initializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=1):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self,F):\n",
    "        W = self.sigma * np.ones((3, 2, F))\n",
    "        pass\n",
    "        return W\n",
    "    \n",
    "    def B(self):\n",
    "#         B = self.sigma * np.random.rand(S)\n",
    "        B = np.array([1, 2, 3]) \n",
    "        pass\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    \"\"\"\n",
    "    入出力サイズN_inからN_outへの\n",
    "    Parameters\n",
    "    ----------\n",
    "    N_in : int\n",
    "      入力サイズ数\n",
    "    N_out : int\n",
    "      出力サイズ数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, N_in=4 , initializer=ones_Initializer, optimizer=SGD, F=3,S=1,P=0):\n",
    "#     def __init__(self, N_in=2, B, initializer=ones_Initializer, optimizer=SGD, F=3,S=1,P=0):\n",
    "        self.initializer = ones_Initializer() \n",
    "        self.optimizer = optimizer()\n",
    "        self.F = F\n",
    "        self.S = S\n",
    "        self.P = P\n",
    "        self.N_in = N_in\n",
    "        self.N_out_cal()\n",
    "        \n",
    "        ini = self.initializer\n",
    "        #初期値を決める\n",
    "        # WとBを決定する\n",
    "        self.W = ini.W(self.F)\n",
    "        self.B = ini.B()    \n",
    "        \n",
    "        opt = self.optimizer\n",
    "        #最適化処理をインスタンス化\n",
    "        \n",
    "        pass\n",
    "    def N_out_cal(self):\n",
    "        N_out = (self.N_in + 2*self.P - self.F)/self.S + 1\n",
    "        self.N_out = int(N_out)\n",
    "    def forward(self, Z):\n",
    "        self.Z = Z\n",
    "        self.creat_index()\n",
    "        A = np.empty((0,0))\n",
    "        box = np.empty((0,0))\n",
    "        for x in range(self.B.shape[0]):\n",
    "            for y in range(self.Z.shape[0]):\n",
    "                for k in range(self.Z.shape[1] - self.W.shape[2] + 1):\n",
    "                    ak = self.Z[y,self.indexes[k]]@self.W[x,y].T\n",
    "                    A = np.append(A,ak)\n",
    "        \n",
    "        A = A.reshape(3,2,2).sum(axis=1)\n",
    "        for z in range(self.B.shape[0]):\n",
    "#             print(self.A)\n",
    "            A[z] = A[z] + self.B[z]\n",
    "        \n",
    "        pass\n",
    "        return A\n",
    "    \n",
    "    def creat_index(self):\n",
    "        self.indexes = np.empty((0,0))\n",
    "        self.index_add = np.empty((0,0))\n",
    "        for i in range(self.Z.shape[1] - self.W.shape[2] + 1):\n",
    "            for j in range(self.W.shape[0]):\n",
    "                self.index_add = np.append(self.index_add,[j + i])\n",
    "\n",
    "        self.indexes = self.index_add.reshape(self.Z.shape[1] - self.W.shape[0] + 1,self.W.shape[0])\n",
    "        self.indexes = self.indexes.astype(\"int\")  \n",
    "      \n",
    "#     def backward(self, dA):\n",
    "#         self.dA = dA\n",
    "#         self.dB = np.array(np.sum(self.dA))\n",
    "#         self.dW = np.zeros((w.shape[0],))\n",
    "#         self.dZ = np.zeros((self.Z.shape[0],))\n",
    "#         for l in range(self.dA.shape[0]):\n",
    "#             delta_w_l = self.dA[l]*x[self.indexes[l]]\n",
    "#             self.dW = self.dW + delta_w_l\n",
    "        \n",
    "#         for h in range(self.dA.shape[0]):\n",
    "#             delta_z_h = delta_a[h]*w\n",
    "#             for m in range(self.dW.shape[0]):\n",
    "#                 self.dZ[m + h] += delta_z_h[m]\n",
    "        \n",
    "#         pass\n",
    "#         # 更新\n",
    "#         self.optimizer.update(self)\n",
    "#         return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = Conv1d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 22.],\n",
       "       [17., 23.],\n",
       "       [18., 24.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力結果\n",
    "a = np.array([[16, 22], [17, 23], [18, 24]]) # shape(3, 2)で、（出力チャンネル数、特徴量数）である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以下　動作確認用データ\n",
    "x_ = np.array([[1,2,3,4],\n",
    "               [2,3,4,5]])\n",
    "\n",
    "\n",
    "w_ = np.array([[[1,1,2],[2,1,1]],\n",
    "              [[2,1,1],[1,1,1]],\n",
    "              [[1,1,1],[1,1,1]]])\n",
    "\n",
    "\n",
    "b_ = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_Initializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=1):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self):\n",
    "        W = np.array([[[1,1,2],[2,1,1]],\n",
    "              [[2,1,1],[1,1,1]],\n",
    "              [[1,1,1],[1,1,1]]])\n",
    "        print(W.shape)\n",
    "        pass\n",
    "        return W\n",
    "    def B(self):\n",
    "#         B = self.sigma * np.random.rand(S)\n",
    "        B = np.array([1,2,3])\n",
    "        pass\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# クラスでのフォワードプロパゲーション動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d_test:\n",
    "    \"\"\"\n",
    "    入出力サイズN_inからN_outへの\n",
    "    Parameters\n",
    "    ----------\n",
    "    N_in : int\n",
    "      入力サイズ数\n",
    "    N_out : int\n",
    "      出力サイズ数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, N_in=4 , initializer=test_Initializer(), optimizer=SGD, F=3,S=1,P=0):\n",
    "#     def __init__(self, N_in=2, B, initializer=ones_Initializer, optimizer=SGD, F=3,S=1,P=0):\n",
    "        self.initializer = test_Initializer()\n",
    "        self.optimizer = optimizer()\n",
    "        self.F = F\n",
    "        self.S = S\n",
    "        self.P = P\n",
    "        self.N_in = N_in\n",
    "        self.N_out_cal()\n",
    "        \n",
    "        ini = self.initializer\n",
    "        #初期値を決める\n",
    "        # WとBを決定する\n",
    "        self.W = ini.W()\n",
    "        self.B = ini.B()    \n",
    "        \n",
    "        opt = self.optimizer\n",
    "        #最適化処理をインスタンス化\n",
    "        \n",
    "        pass\n",
    "    def N_out_cal(self):\n",
    "        N_out = (self.N_in + 2*self.P - self.F)/self.S + 1\n",
    "        self.N_out = int(N_out)\n",
    "    def forward(self, Z):\n",
    "        self.Z = Z\n",
    "        self.creat_index()\n",
    "        A = np.empty((0,0))\n",
    "        box = np.empty((0,0))\n",
    "        for o in range(self.B.shape[0]):\n",
    "            for p in range(self.Z.shape[0]):\n",
    "                for k in range(self.Z.shape[1] - self.W.shape[2] + 1):\n",
    "                    ak = self.Z[p,self.indexes[k]]@self.W[o,p].T\n",
    "                    A = np.append(A,ak)\n",
    "        \n",
    "        A = A.reshape(3,2,2).sum(axis=1)\n",
    "        for q in range(self.B.shape[0]):\n",
    "#             print(self.A)\n",
    "            A[q] = A[q] + self.B[q]\n",
    "        return A\n",
    "    \n",
    "    def creat_index(self):\n",
    "        self.indexes = np.empty((0,0))\n",
    "        self.index_add = np.empty((0,0))\n",
    "        for i in range(self.Z.shape[1] - self.W.shape[2] + 1):\n",
    "            for j in range(self.W.shape[0]):\n",
    "                self.index_add = np.append(self.index_add,[j + i])\n",
    "\n",
    "        self.indexes = self.index_add.reshape(self.Z.shape[1] - self.W.shape[0] + 1,self.W.shape[0])\n",
    "        self.indexes = self.indexes.astype(\"int\")  \n",
    "      \n",
    "#     def backward(self, dA):\n",
    "#         self.dA = dA\n",
    "#         self.dB = np.array(np.sum(self.dA))\n",
    "#         self.dW = np.zeros((w.shape[0],))\n",
    "#         self.dZ = np.zeros((self.Z.shape[0],))\n",
    "#         for l in range(self.dA.shape[0]):\n",
    "#             delta_w_l = self.dA[l]*x[self.indexes[l]]\n",
    "#             self.dW = self.dW + delta_w_l\n",
    "        \n",
    "#         for h in range(self.dA.shape[0]):\n",
    "#             delta_z_h = delta_a[h]*w\n",
    "#             for m in range(self.dW.shape[0]):\n",
    "#                 self.dZ[m + h] += delta_z_h[m]\n",
    "        \n",
    "#         pass\n",
    "#         # 更新\n",
    "#         self.optimizer.update(self)\n",
    "#         return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "cv1 = Conv1d_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21., 29.],\n",
       "       [18., 25.],\n",
       "       [18., 24.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1.forward(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# フォワードの出力(回答)\n",
    "out_ = np.array([[21,29],\n",
    "                [18,25],\n",
    "                [18,24]])\n",
    "\n",
    "# バック用の入力\n",
    "loss_ = np.array([[9,11],\n",
    "                [32,35],\n",
    "                [52,56]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([[1,2,3,4],\n",
    "               [2,3,4,5]])\n",
    "da = np.array([[9,11],\n",
    "                [32,35],\n",
    "                [52,56]])\n",
    "w =  np.array([[[1,1,2],[2,1,1]],\n",
    "              [[2,1,1],[1,1,1]],\n",
    "              [[1,1,1],[1,1,1]]])\n",
    "b_ = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 関数の状態でのバックプロパゲーション動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(dA_ori):\n",
    "    #dBの計算\n",
    "    dB_all = np.array(np.sum(dA_ori,axis=1))\n",
    "    \n",
    "    #dWの計算\n",
    "    dW_all = np.zeros((w.shape[0],Z.shape[0],w.shape[2]))#出力チャンネル数、入力チャンネル数、フィルタサイズ\n",
    "    dZ_all = np.zeros((Z.shape[0],Z.shape[1],))#入力チャンネル数、入力特徴量数\n",
    "    #     print(dW_all.shape)\n",
    "    for chanel in range(dA_ori.shape[0]):\n",
    "        dA = dA_ori[chanel]\n",
    "        dW = np.zeros((Z.shape[0],w.shape[0],))#入力チャンネル数、フィルタサイズ\n",
    "        delta_w_l = np.zeros((Z.shape[0],w.shape[2],))#入力チャンネル数、フィルタサイズ\n",
    "#         print(delta_w_l)\n",
    "        \n",
    "        dZ = np.zeros((Z.shape[0],Z.shape[1],))#入力チャンネル数、入力特徴量数\n",
    "        delta_z_h_a = np.zeros(w.shape[1])\n",
    "        delta_z_h_box = np.zeros((dA.shape[0],dA.shape[0],w.shape[2]))\n",
    "    #     print(delta_z_h_box.shape)\n",
    "    #     print(delta_z_h_a.shape)\n",
    "        delta_z_h = np.zeros((Z.shape[0],w.shape[2],))\n",
    "    #     print(delta_z_h)\n",
    "#         print(dA.shape)\n",
    "        for a in range(Z.shape[0]):\n",
    "            for l in range(dA.shape[0]):\n",
    "#                 print(dA[l]*Z[a,indexes[l]])\n",
    "    #             print(delta_w_l[a])\n",
    "                delta_w_l[a] = dA[l]*Z[a,indexes[l]]\n",
    "    #             print(a)\n",
    "    #             print(delta_w_l[a])\n",
    "                dW[a] = dW[a] + delta_w_l[a]\n",
    "#         print(dW)\n",
    "        dW_all[chanel] =dW \n",
    "        \n",
    "        for b in range(dA.shape[0]):\n",
    "            for h in range(dA.shape[0]):\n",
    "    #             print((dA[h]*w[b]).shape)\n",
    "#                 print(w[chanel,b])\n",
    "                delta_z_h_a = dA[h]*w[chanel,b]\n",
    "#                 print(delta_z_h_a)\n",
    "#                 print(delta_z_h_a)\n",
    "                delta_z_h_box[b,h] += delta_z_h_a\n",
    "#         print(delta_z_h_box.shape)\n",
    "        for c in range(dA.shape[0]):\n",
    "            for d in range(dA.shape[0]):\n",
    "    #             print(delta_z_h_box[c,d])\n",
    "    #             print(indexes[d])\n",
    "    #             print(dZ[c,indexes[d]])\n",
    "                dZ[c,indexes[d]] += delta_z_h_box[c,d]\n",
    "        dZ_all += dZ\n",
    "#         print(dZ)\n",
    "    #                 print(m)\n",
    "    #                 print(dW.shape[0])\n",
    "    #                 print(dZ[m + h].shape)\n",
    "    #                 print(delta_z_h[m].shape)\n",
    "    #                 print(delta_z_h[b,m])\n",
    "\n",
    "    #                 dZ[b,indexes[m]] += delta_z_h[b,m]\n",
    "#     print(dZ_all)\n",
    "    return dA_ori,dB_all,dW_all,dZ_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz = backward(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[125. 230. 204. 113.]\n",
      " [102. 206. 195. 102.]]\n"
     ]
    }
   ],
   "source": [
    "dA,dB,dW,dZ = backward(da)\n",
    "print(dZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バックの出力(回答)\n",
    "x_delta = np.array\\\n",
    "([[125,230,204,113],\\\n",
    "[102,206,195,102]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 31.  51.  71.]\n",
      "  [ 51.  71.  91.]]\n",
      "\n",
      " [[102. 169. 236.]\n",
      "  [169. 236. 303.]]\n",
      "\n",
      " [[164. 272. 380.]\n",
      "  [272. 380. 488.]]]\n"
     ]
    }
   ],
   "source": [
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バックの出力(回答)\n",
    "w_delta = np.array\\\n",
    "([[[31,51,71],\n",
    "   [51,71,91]],\n",
    "  \n",
    "[[102,169,236],\n",
    " [169,236,303]],\n",
    "  \n",
    "[[164,272,380],\n",
    " [272,380,488]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# クラスでの全体結合の動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d_marge:\n",
    "    \"\"\"\n",
    "    入出力サイズN_inからN_outへの\n",
    "    Parameters\n",
    "    ----------\n",
    "    N_in : int\n",
    "      入力サイズ数\n",
    "    N_out : int\n",
    "      出力サイズ数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, N_in=4 , initializer=test_Initializer(), optimizer=SGD, F=3,S=1,P=0):\n",
    "#     def __init__(self, N_in=2, B, initializer=ones_Initializer, optimizer=SGD, F=3,S=1,P=0):\n",
    "        self.initializer = test_Initializer()\n",
    "        self.optimizer = optimizer()\n",
    "        self.F = F\n",
    "        self.S = S\n",
    "        self.P = P\n",
    "        self.N_in = N_in\n",
    "        self.N_out_cal()\n",
    "        \n",
    "        ini = self.initializer\n",
    "        #初期値を決める\n",
    "        # WとBを決定する\n",
    "        self.W = ini.W()\n",
    "        self.B = ini.B()    \n",
    "        \n",
    "        opt = self.optimizer\n",
    "        #最適化処理をインスタンス化\n",
    "        \n",
    "        pass\n",
    "    def N_out_cal(self):\n",
    "        N_out = (self.N_in + 2*self.P - self.F)/self.S + 1\n",
    "        self.N_out = int(N_out)\n",
    "    def forward(self, Z):\n",
    "        self.Z = Z\n",
    "        self.creat_index()\n",
    "        A = np.empty((0,0))\n",
    "        box = np.empty((0,0))\n",
    "#         print(self.Z.shape)\n",
    "#         print(self.W.shape)\n",
    "        for o in range(self.B.shape[0]):\n",
    "            for p in range(self.Z.shape[0]):\n",
    "                for k in range(self.Z.shape[1] - self.W.shape[2] + 1):\n",
    "#                     print(self.indexes[k])\n",
    "#                     print(self.Z[p,self.indexes[k]])\n",
    "#                     print(self.W[o,p].T)\n",
    "                    ak = self.Z[p,self.indexes[k]]@self.W[o,p].T\n",
    "                    A = np.append(A,ak)\n",
    "        \n",
    "        A = A.reshape(3,2,2).sum(axis=1)\n",
    "        for q in range(self.B.shape[0]):\n",
    "#             print(self.A)\n",
    "            A[q] = A[q] + self.B[q]\n",
    "        return A\n",
    "    \n",
    "    def creat_index(self):\n",
    "        self.indexes = np.empty((0,0))\n",
    "        self.index_add = np.empty((0,0))\n",
    "        for i in range(self.Z.shape[1] - self.W.shape[2] + 1):\n",
    "            for j in range(self.W.shape[0]):\n",
    "                print(self.index_add,[j + i])\n",
    "                self.index_add = np.append(self.index_add,[j + i])\n",
    "\n",
    "#         print(self.Z.shape[1])\n",
    "#         print(self.W.shape[2])\n",
    "#         print(self.W.shape[0])\n",
    "                \n",
    "        print(self.Z.shape[1] - self.W.shape[2] + 1,self.W.shape[0])\n",
    "        self.indexes = self.index_add.reshape(self.Z.shape[1] - self.W.shape[0] + 1,self.W.shape[0])\n",
    "        self.indexes = self.indexes.astype(\"int\")  \n",
    "      \n",
    "    def backward(self,dA_ori):\n",
    "        #dBの計算\n",
    "        dB_all = np.array(np.sum(dA_ori,axis=1))\n",
    "        self.dB = dB_all\n",
    "        \n",
    "        #dWの計算\n",
    "        dW_all = np.zeros((self.W.shape[0],self.Z.shape[0],self.W.shape[2]))#出力チャンネル数、入力チャンネル数、フィルタサイズ\n",
    "        dZ_all = np.zeros((self.Z.shape[0],self.Z.shape[1],))#入力チャンネル数、入力特徴量数\n",
    "        for chanel in range(dA_ori.shape[0]):\n",
    "            dA = dA_ori[chanel]\n",
    "            dW = np.zeros((self.Z.shape[0],self.W.shape[0],))#入力チャンネル数、フィルタサイズ\n",
    "            delta_w_l = np.zeros((self.Z.shape[0],self.W.shape[2],))#入力チャンネル数、フィルタサイズ\n",
    "            dZ = np.zeros((self.Z.shape[0],self.Z.shape[1],))#入力チャンネル数、入力特徴量数\n",
    "            delta_z_h_a = np.zeros(self.W.shape[1])\n",
    "            delta_z_h_box = np.zeros((dA.shape[0],dA.shape[0],self.W.shape[2]))\n",
    "            delta_z_h = np.zeros((Z.shape[0],self.W.shape[2],))\n",
    "            \n",
    "            #dWの計算\n",
    "            for a in range(self.Z.shape[0]):\n",
    "                for l in range(dA.shape[0]):\n",
    "                    delta_w_l[a] = dA[l]*self.Z[a,self.indexes[l]]\n",
    "                    dW[a] = dW[a] + delta_w_l[a]\n",
    "            dW_all[chanel] =dW\n",
    "            self.dW = dW_all\n",
    "            \n",
    "            #dZの計算\n",
    "            for b in range(dA.shape[0]):\n",
    "                for h in range(dA.shape[0]):\n",
    "                    delta_z_h_a = dA[h]*w[chanel,b]\n",
    "                    delta_z_h_box[b,h] += delta_z_h_a\n",
    "            for c in range(dA.shape[0]):\n",
    "                for d in range(dA.shape[0]):\n",
    "                    dZ[c,self.indexes[d]] += delta_z_h_box[c,d]\n",
    "            dZ_all += dZ\n",
    "            self.dZ = dZ_all\n",
    "            \n",
    "        self.optimizer.update(self)\n",
    "        return dZ_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "cv1 = Conv1d_marge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [0]\n",
      "[0.] [1]\n",
      "[0. 1.] [2]\n",
      "[0. 1. 2.] [1]\n",
      "[0. 1. 2. 1.] [2]\n",
      "[0. 1. 2. 1. 2.] [3]\n",
      "2 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[21., 29.],\n",
       "       [18., 25.],\n",
       "       [18., 24.]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1.forward(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[125., 230., 204., 113.],\n",
       "       [102., 206., 195., 102.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1.backward(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題8】学習と推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 784)\n",
      "(59970, 784)\n",
      "(30, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train_1, X_val, y_train_1, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.9995)\n",
    "print(X_train_1.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)\n",
    "print(y_train_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNNに組み込むために調整を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.005):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        pass\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.rand(n_nodes2)\n",
    "        pass\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer=SimpleInitializer, optimizer=SGD):\n",
    "        self.initializer = SimpleInitializer\n",
    "        self.optimizer = optimizer\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        \n",
    "        init = self.initializer()\n",
    "        #初期値を決める\n",
    "        # WとBを決定する\n",
    "        self.W = init.W(self.n_nodes1,self.n_nodes2)\n",
    "        self.B = init.B(self.n_nodes2)        \n",
    "        \n",
    "        opt = self.optimizer\n",
    "        #最適化処理をインスタンス化\n",
    "        \n",
    "        pass\n",
    "    def forward(self, Z):\n",
    "        self.Z = Z\n",
    "        A = self.Z@self.W + self.B\n",
    "        self.A = A\n",
    "        \n",
    "        pass\n",
    "        return A\n",
    "    def backward(self, dA):\n",
    "        self.dA = dA\n",
    "        self.dB = self.dA.mean(axis=0)\n",
    "        self.dW = self.Z.T@self.dA\n",
    "        dZ = self.dA@self.W.T\n",
    "        \n",
    "        pass\n",
    "        # 更新\n",
    "        self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ソフトマックス\n",
    "class softmax:\n",
    "    def __init__(self):\n",
    "        \n",
    "        pass\n",
    "    def forward(self, A):\n",
    "        Z = (np.exp(A).T/np.exp(A).sum(axis=1)).T\n",
    "         \n",
    "        return Z\n",
    "    def backward(self, Z, Y):\n",
    "        dA = Z - Y\n",
    "        \n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# タンジェントハイポ\n",
    "class tanh:\n",
    "    def __init__(self):\n",
    "        \n",
    "        pass\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = np.tanh(A)\n",
    "        self.Z = Z       \n",
    "        return Z        \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ*(1-np.tanh(self.A)**2)\n",
    "    \n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ミニバッチ\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad_mean:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.001, h=0):\n",
    "        self.lr = lr\n",
    "        self.h_W = h\n",
    "        self.h_B = h\n",
    "    def update(self, layer):\n",
    "        self.h_W += ((layer.dW/layer.dW.shape[0])*(layer.dW/layer.dW.shape[0])).mean()\n",
    "#         print(self.h_W.shape)\n",
    "        #self.h += ((layer.dW.mean(axis=1))*(layer.dW.mean(axis=1)))#.sum()\n",
    "      \n",
    "        layer.W = layer.W - self.lr/((self.h_W**0.5) + 0.001) *layer.dW/layer.dW.shape[0]\n",
    "        #if self.h >= 0.2:\n",
    "            #layer.W = layer.W - self.lr/(self.h**0.5)*layer.dW + 1e-7\n",
    "#         else:\n",
    "#             layer.W = layer.W - self.lr*layer.dW\n",
    "        self.h_B += ((layer.dB/layer.dB.shape[0])*(layer.dB/layer.dB.shape[0])).mean()\n",
    "#         print('dB',layer.dB.shape)#20\n",
    "#         print('h_B',self.h_B.shape)#20\n",
    "#         print('B',layer.B.shape)#10\n",
    "#         print('dB.mean',layer.dB.mean(axis=0).shape)#shapeない\n",
    "        layer.B = layer.B - self.lr/((self.h_B**0.5) + 0.001) *layer.dB.mean(axis=0)/layer.dB.shape[0]\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConV1d_Initializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=1, in_cha=400, out_cha=398, F_size=3):\n",
    "        self.sigma = sigma\n",
    "        self.in_cha = in_cha\n",
    "        self.out_cha = out_cha\n",
    "        self.F_size = F_size\n",
    "        \n",
    "    def W(self):\n",
    "        W = np.random.randn(self.in_cha, self.out_cha, self.F_size)\n",
    "        print(W.shape)\n",
    "        pass\n",
    "        return W\n",
    "    def B(self):\n",
    "        B = self.sigma * np.random.rand(self.out_cha)\n",
    "#         B = np.array([1,2,3])\n",
    "        pass\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d_marge_DNN:\n",
    "    \"\"\"\n",
    "    入出力サイズN_inからN_outへの\n",
    "    Parameters\n",
    "    ----------\n",
    "    N_in : int\n",
    "      入力サイズ数\n",
    "    N_out : int\n",
    "      出力サイズ数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, N_in=400 , initializer=test_Initializer(), optimizer=SGD, F=3,S=1,P=0):\n",
    "#     def __init__(self, N_in=2, B, initializer=ones_Initializer, optimizer=SGD, F=3,S=1,P=0):\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        self.F = F\n",
    "        self.S = S\n",
    "        self.P = P\n",
    "        self.N_in = N_in\n",
    "        self.N_out_cal()\n",
    "        \n",
    "        ini = self.initializer\n",
    "        #初期値を決める\n",
    "        # WとBを決定する\n",
    "        self.W = ini.W()\n",
    "        self.B = ini.B()    \n",
    "        \n",
    "        opt = self.optimizer\n",
    "        #最適化処理をインスタンス化\n",
    "        \n",
    "        pass\n",
    "    def N_out_cal(self):\n",
    "        N_out = (self.N_in + 2*self.P - self.F)/self.S + 1\n",
    "        self.N_out = int(N_out)\n",
    "    def forward(self, Z):\n",
    "        self.Z = Z\n",
    "        self.creat_index()\n",
    "        A = np.empty((0,0))\n",
    "        box = np.empty((0,0))\n",
    "#         print(self.Z.shape)\n",
    "#         print(self.W.shape)\n",
    "#         print(self.indexes)\n",
    "        print(self.B.shape[0])\n",
    "        print(self.Z.shape[0])\n",
    "        for o in range(self.B.shape[0]):\n",
    "            for p in range(30):\n",
    "                for k in range(398):\n",
    "#                     print(self.Z.shape)\n",
    "#                     print(400 - self.W.shape[2] + 1)\n",
    "                    v = self.Z[p,self.indexes[k]]\n",
    "#                     print(self.indexes[k].shape)\n",
    "                    u = self.W[o,p].T\n",
    "#                     print(u.shape)\n",
    "                    ak = v@u\n",
    "                    A = np.append(A,ak)\n",
    "        \n",
    "        A = A.reshape(3,2,2).sum(axis=1)\n",
    "        for q in range(self.B.shape[0]):\n",
    "#             print(self.A)\n",
    "            A[q] = A[q] + self.B[q]\n",
    "        return A\n",
    "    \n",
    "    def creat_index(self):\n",
    "        self.indexes = np.empty((0,0))\n",
    "        self.index_add = np.empty((0,0))\n",
    "#         print(self.Z.shape[1])\n",
    "#         print(self.W.shape[2])\n",
    "#         print(self.W.shape[0])\n",
    "        for i in range(398):\n",
    "            for j in range(3):\n",
    "                print(self.index_add.shape)\n",
    "#                 print(self.index_add,[j + i])\n",
    "                self.index_add = np.append(self.index_add,[j + i])\n",
    "        \n",
    "#         print(self.Z.shape[1] - self.W.shape[2] + 1,self.W.shape[0])\n",
    "        self.indexes = self.index_add.reshape(self.Z.shape[1] - self.W.shape[2] + 1,3)\n",
    "        \n",
    "        self.indexes = self.indexes.astype(\"int\")  \n",
    "#         print(self.indexes)\n",
    "      \n",
    "    def backward(self,dA_ori):\n",
    "        #dBの計算\n",
    "        dB_all = np.array(np.sum(dA_ori,axis=1))\n",
    "        self.dB = dB_all\n",
    "        \n",
    "        #dWの計算\n",
    "        dW_all = np.zeros((self.W.shape[0],self.Z.shape[0],self.W.shape[2]))#出力チャンネル数、入力チャンネル数、フィルタサイズ\n",
    "        dZ_all = np.zeros((self.Z.shape[0],self.Z.shape[1],))#入力チャンネル数、入力特徴量数\n",
    "        for chanel in range(dA_ori.shape[0]):\n",
    "            dA = dA_ori[chanel]\n",
    "            dW = np.zeros((self.Z.shape[0],self.W.shape[0],))#入力チャンネル数、フィルタサイズ\n",
    "            delta_w_l = np.zeros((self.Z.shape[0],self.W.shape[2],))#入力チャンネル数、フィルタサイズ\n",
    "            dZ = np.zeros((self.Z.shape[0],self.Z.shape[1],))#入力チャンネル数、入力特徴量数\n",
    "            delta_z_h_a = np.zeros(self.W.shape[1])\n",
    "            delta_z_h_box = np.zeros((dA.shape[0],dA.shape[0],self.W.shape[2]))\n",
    "            delta_z_h = np.zeros((Z.shape[0],self.W.shape[2],))\n",
    "            \n",
    "            #dWの計算\n",
    "            for a in range(self.Z.shape[0]):\n",
    "                for l in range(dA.shape[0]):\n",
    "                    delta_w_l[a] = dA[l]*self.Z[a,self.indexes[l]]\n",
    "                    dW[a] = dW[a] + delta_w_l[a]\n",
    "            dW_all[chanel] =dW\n",
    "            self.dW = dW_all\n",
    "\n",
    "            \n",
    "            #dZの計算\n",
    "            for b in range(dA.shape[0]):\n",
    "                for h in range(dA.shape[0]):\n",
    "                    delta_z_h_a = dA[h]*w[chanel,b]\n",
    "                    delta_z_h_box[b,h] += delta_z_h_a\n",
    "            for c in range(dA.shape[0]):\n",
    "                for d in range(dA.shape[0]):\n",
    "                    dZ[c,self.indexes[d]] += delta_z_h_box[c,d]\n",
    "            dZ_all += dZ\n",
    "            self.dZ = dZ_all\n",
    "            \n",
    "        self.optimizer.update(self)\n",
    "        return dZ_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "\n",
    "    def __init__(self,num_iter = 1,lr = 0.001, verbose = True):\n",
    "        self.verbose = verbose\n",
    "        self.num_iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        self.n_features = 784\n",
    "        self.n_nodes1 = 400\n",
    "        self.n_nodes2 = 398\n",
    "        self.n_output = 10\n",
    "        self.alpha = 0.001\n",
    "        self.rec_loss = [] \n",
    "        self.rec_val_loss = []         \n",
    "        \n",
    "        pass\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        #最適化手法のインスタンス化\n",
    "        optimizer1 = AdaGrad_mean(lr = 0.04)\n",
    "        optimizer2 = Conv1d_marge_DNN()\n",
    "        \n",
    "        initializer1 = SimpleInitializer()\n",
    "        initializer2 = ConV1d_Initializer()\n",
    "#         initializer3 = ConV1d_Initializer()\n",
    "        \n",
    "        #層の数、各層の特徴数（インプット＆アウトプット）、初期値設定、最適化手法、活性化関数の種類を設定\n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, initializer1, optimizer1)\n",
    "        self.activation1 = tanh()\n",
    "        self.FC2 = Conv1d_marge_DNN(initializer=initializer2, optimizer=optimizer2)\n",
    "        self.activation2 = tanh()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, initializer1, optimizer1)\n",
    "        self.activation3 = softmax()\n",
    "\n",
    "        #ミニバッチ２０で学習\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "#         get_mini_batch = GetMiniBatch(self.X, self.y, batch_size=20)\n",
    "        self.z_all = np.empty((0, 10),dtype=np.float)\n",
    "        for i in range(self.num_iter):\n",
    "    # フォワードプロパゲーション\n",
    "            A1 = self.FC1.forward(X)\n",
    "            Z1 = self.activation1.forward(A1)\n",
    "#             print(Z1.shape)\n",
    "            A2 = self.FC2.forward(Z1)\n",
    "            Z2 = self.activation2.forward(A2)\n",
    "            A3 = self.FC3.forward(Z2)\n",
    "            Z3 = self.activation3.forward(A3)\n",
    "            self.Z3 = Z3\n",
    "    # バックプロパゲーション\n",
    "            dA3 = self.activation3.backward(Z3, y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "            dZ2 = self.FC3.backward(dA3)\n",
    "            dA2 = self.activation2.backward(dZ2)\n",
    "            dZ1 = self.FC2.backward(dA2)\n",
    "            dA1 = self.activation1.backward(dZ1)\n",
    "            dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
    "            self.loss_entropy(y)\n",
    "            #フィット後のB、Wを抜き出す\n",
    "            self.B1 = self.FC1.B\n",
    "            self.B2 = self.FC2.B\n",
    "            self.B3 = self.FC3.B\n",
    "            \n",
    "            self.W1 = self.FC1.W\n",
    "            self.W2 = self.FC2.W\n",
    "            self.W3 = self.FC3.W\n",
    "            self.val_loss_entropy()\n",
    "                \n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print()\n",
    "        pass\n",
    "\n",
    "    def loss_entropy(self,y_train_batch):\n",
    "        self.loss = -1/self.Z3.shape[0]*(y_train_batch*(np.log(self.Z3))).sum()  \n",
    "        self.rec_loss.append(self.loss)\n",
    "        \n",
    "    def val_loss_entropy(self):\n",
    "        self.a1 = self.X_val@self.W1 + self.B1\n",
    "        self.z1 = np.tanh(self.a1)\n",
    "        self.a2 = self.z1@self.W2 + self.B2\n",
    "        self.z2 = np.tanh(self.a2)\n",
    "        self.a3 = self.z2@self.W3 + self.B3\n",
    "        self.z3 = self.activation3.forward(self.a3)        \n",
    "        self.val_loss = -1/self.z3.shape[0]*(self.y_val*(np.log(self.z3))).sum()  \n",
    "        self.rec_val_loss.append(self.val_loss)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        z_all = np.empty((0, 10),dtype=np.float)\n",
    "#         print(z_all.shape)\n",
    "        self.a1 = X_test@self.W1 + self.B1\n",
    "        self.z1 = np.tanh(self.a1)\n",
    "        self.a2 = self.z1@self.W2 + self.B2\n",
    "        self.z2 = np.tanh(self.a2)\n",
    "        self.a3 = self.z2@self.W3 + self.B3\n",
    "        self.z3 = self.activation3.forward(self.a3)\n",
    "        z_all = np.concatenate([z_all,self.z3])\n",
    "        z_all_index = np.argmax(z_all, axis=1)\n",
    "        \n",
    "        pass\n",
    "        return z_all, z_all_index"
   ]
  },
 
